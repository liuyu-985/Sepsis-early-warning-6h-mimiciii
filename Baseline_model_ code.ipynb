{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Baseline model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "a. Catboost for tabular data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7L7Prr4utkx",
        "outputId": "359cdc8c-91a2-474c-93d0-c0be1f6411be"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "save_dir = \"/content/drive/MyDrive/CIS_678_final_project/\"\n",
        "\n",
        "from pathlib import Path\n",
        "DATA = Path('/content/drive/MyDrive/CIS_678_final_project')\n",
        "\n",
        "import pandas as pd\n",
        "def read_tabular(fname):  # tabular CSVs with timestamp column \"t\"\n",
        "    return pd.read_csv(DATA/fname, parse_dates=[\"t\"], na_values=[\"NULL\"])\n",
        "\n",
        "def read_text(fname):\n",
        "    return pd.read_csv(DATA/fname, na_values=[\"NULL\"])\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "def report_metrics(y_true, p):\n",
        "    auroc = roc_auc_score(y_true, p)\n",
        "    auprc = average_precision_score(y_true, p)\n",
        "    return {\"AUROC\": auroc, \"AUPRC\": auprc}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxxsQW_S0HXA",
        "outputId": "dab7c124-e85f-4946-848d-d652a9c4843b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "train_tab = read_tabular(\"features6h_rich_train.csv\")\n",
        "test_tab = read_tabular(\"features6h_rich_test.csv\")\n",
        "\n",
        "\n",
        "# counts of 0 and 1\n",
        "y_tr = train_tab[\"label6h\"].astype(int)\n",
        "counts_tr = y_tr.value_counts().sort_index()\n",
        "print(counts_tr)\n",
        "\n",
        "y_te = test_tab[\"label6h\"].astype(int)\n",
        "counts_te = y_te.value_counts().sort_index()\n",
        "print(counts_te)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "id": "ES114UZLRp1r",
        "outputId": "31c8fd7a-23c4-465d-b86b-96889cd4f01a"
      },
      "outputs": [],
      "source": [
        "train_tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "W5Eem86B4kiC",
        "outputId": "c5073f3e-9b3e-442e-df60-4efc42f13430"
      },
      "outputs": [],
      "source": [
        "train_tab.iloc[15:20, :15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpoA9m0x6fhT",
        "outputId": "2c703bc8-0400-45fe-93f2-1f47a4f1db99"
      },
      "outputs": [],
      "source": [
        "train_tab_columns = train_tab.columns\n",
        "train_tab_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvbC1XTq4TN0",
        "outputId": "d5176560-67cd-4b8e-88e5-7bbb335a1908"
      },
      "outputs": [],
      "source": [
        "!pip install -q catboost\n",
        "import numpy as np, pandas as pd, os, json, hashlib\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, average_precision_score, precision_score,\n",
        "    recall_score, f1_score, confusion_matrix\n",
        ")\n",
        "\n",
        "TRAIN_CSV = \"/content/drive/MyDrive/CIS_678_final_project/features6h_rich_train.csv\"\n",
        "TEST_CSV  = \"/content/drive/MyDrive/CIS_678_final_project/features6h_rich_test.csv\"\n",
        "\n",
        "train_tab = pd.read_csv(TRAIN_CSV, parse_dates=[\"t\"], low_memory=False)\n",
        "test_tab  = pd.read_csv(TEST_CSV,  parse_dates=[\"t\"], low_memory=False)\n",
        "\n",
        "GROUP = [\"subject_id\",\"hadm_id\",\"icustay_id\"]\n",
        "TIME  = \"t\"\n",
        "LABEL = \"label6h\"\n",
        "\n",
        "# Safety: no train/test overlap\n",
        "for key in GROUP:\n",
        "    overlap = set(train_tab[key]).intersection(set(test_tab[key]))\n",
        "    assert len(overlap) == 0, f\"Train/Test leakage via {key}: {len(overlap)} overlaps\"\n",
        "\n",
        "# cast categoricals to string\n",
        "for c in [\"sex\", \"dbsource\"]:\n",
        "    if c in train_tab.columns: train_tab[c] = train_tab[c].astype(str)\n",
        "    if c in test_tab.columns:  test_tab[c]  = test_tab[c].astype(str)\n",
        "\n",
        "# speed: float32 and replace inf\n",
        "for df in (train_tab, test_tab):\n",
        "    num_cols_df = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
        "    df[num_cols_df] = df[num_cols_df].astype(\"float32\")\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "EXCLUDE = set(GROUP + [TIME, LABEL, \"split\"])\n",
        "CAT_KEEP = [c for c in [\"sex\",\"dbsource\"] if c in train_tab.columns]\n",
        "\n",
        "def is_num(col): return pd.api.types.is_numeric_dtype(train_tab[col])\n",
        "num_cols = [c for c in train_tab.columns if c not in EXCLUDE and is_num(c) and c not in CAT_KEEP]\n",
        "\n",
        "# order-preserving dedup; ensure test has same columns\n",
        "def dedup(seq): return list(dict.fromkeys(seq))\n",
        "FEATURES = [c for c in dedup(num_cols + CAT_KEEP) if c in test_tab.columns]\n",
        "\n",
        "def cat_idx(all_cols, cats):\n",
        "    s = set(cats)\n",
        "    return [i for i, c in enumerate(all_cols) if c in s]\n",
        "\n",
        "cat_features_idx = cat_idx(FEATURES, [c for c in CAT_KEEP if c in FEATURES])\n",
        "\n",
        "X      = train_tab[FEATURES]\n",
        "Xt     = test_tab[FEATURES]\n",
        "y      = train_tab[LABEL].astype(int).to_numpy()\n",
        "y_test = test_tab[LABEL].astype(int).to_numpy()\n",
        "\n",
        "\n",
        "tvals = pd.to_datetime(train_tab[TIME]).to_numpy()\n",
        "order = np.argsort(tvals)\n",
        "N_CHUNKS = 5\n",
        "fold_ids = np.full(len(train_tab), -1, int)\n",
        "for k, idx in enumerate(np.array_split(order, N_CHUNKS)):\n",
        "    fold_ids[idx] = k\n",
        "groups = train_tab[\"hadm_id\"].to_numpy()\n",
        "\n",
        "pos_rate = float(y.mean())\n",
        "scale_pos_weight = (1.0 - pos_rate) / max(pos_rate, 1e-12)\n",
        "\n",
        "# Try GPU; fallback to CPU if it errors later\n",
        "USE_GPU = True  # set False if you want to force CPU\n",
        "\n",
        "cb_params = dict(\n",
        "    task_type=(\"GPU\" if USE_GPU else \"CPU\"),\n",
        "    devices=\"0\" if USE_GPU else None,\n",
        "    loss_function=\"Logloss\",\n",
        "    eval_metric=\"PRAUC\",\n",
        "    depth=6,\n",
        "    learning_rate=0.05,\n",
        "    iterations=2000,\n",
        "    l2_leaf_reg=3.0,\n",
        "    class_weights=[1.0, scale_pos_weight],\n",
        "    bootstrap_type=\"Bernoulli\",\n",
        "    subsample=0.6,\n",
        "    # rsm=0.8,\n",
        "    leaf_estimation_iterations=4,\n",
        "    use_best_model=True,\n",
        "    od_type=\"Iter\",\n",
        "    od_wait=120,\n",
        "    random_seed=42,\n",
        "    verbose=False,\n",
        "    allow_writing_files=False,\n",
        ")\n",
        "\n",
        "# If you want RSM for CPU runs, add it conditionally:\n",
        "if not USE_GPU:\n",
        "    cb_params[\"rsm\"] = 0.8\n",
        "\n",
        "def metrics(y_true, p):\n",
        "    return {\"AUROC\": roc_auc_score(y_true, p),\n",
        "            \"AUPRC\": average_precision_score(y_true, p)}\n",
        "\n",
        "oof = np.full(len(train_tab), np.nan, float)\n",
        "\n",
        "for k in range(1, N_CHUNKS):\n",
        "    va_idx = np.where(fold_ids == k)[0]\n",
        "    tr_pool_idx = np.where(fold_ids <  k)[0]\n",
        "\n",
        "    # HADM-disjoint\n",
        "    va_hadm = set(groups[va_idx])\n",
        "    tr_idx = tr_pool_idx[~np.isin(groups[tr_pool_idx], list(va_hadm))]\n",
        "\n",
        "    if len(tr_idx)==0 or len(va_idx)==0:\n",
        "        print(f\"[Base] skip chunk {k}: tr={len(tr_idx)} va={len(va_idx)}\")\n",
        "        continue\n",
        "\n",
        "    cb = CatBoostClassifier(**cb_params)\n",
        "    cb.fit(\n",
        "        Pool(X.iloc[tr_idx], y[tr_idx], cat_features=cat_features_idx),\n",
        "        eval_set=Pool(X.iloc[va_idx], y[va_idx], cat_features=cat_features_idx)\n",
        "    )\n",
        "    oof[va_idx] = cb.predict_proba(X.iloc[va_idx])[:,1]\n",
        "    print(f\"[Base] chunk {k}:\", metrics(y[va_idx], oof[va_idx]))\n",
        "\n",
        "used = ~np.isnan(oof)\n",
        "print(\"[Base] OOF (valid rows):\", metrics(y[used], oof[used]))\n",
        "\n",
        "\n",
        "def sweep_thresholds(y_true, p, grid=None):\n",
        "    grid = grid or np.linspace(0.05, 0.95, 19)\n",
        "    rows = []\n",
        "    for thr in grid:\n",
        "        yhat = (p >= thr).astype(int)\n",
        "        rows.append({\n",
        "            \"threshold\": float(thr),\n",
        "            \"precision\": precision_score(y_true, yhat, zero_division=0),\n",
        "            \"recall\":    recall_score(y_true, yhat, zero_division=0),\n",
        "            \"f1\":        f1_score(y_true, yhat, zero_division=0)\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "thr_table = sweep_thresholds(y[used], oof[used])\n",
        "best_row = thr_table.sort_values([\"f1\",\"recall\",\"precision\"], ascending=False).iloc[0]\n",
        "BEST_THR = float(best_row[\"threshold\"])\n",
        "print(\"\\n[Base] OOF threshold table:\\n\", thr_table)\n",
        "print(f\"\\nSelected THRESH={BEST_THR:.3f} | \"\n",
        "      f\"P={best_row['precision']:.3f} R={best_row['recall']:.3f} F1={best_row['f1']:.3f}\")\n",
        "\n",
        "# Train full model and score TEST\n",
        "cb_full = CatBoostClassifier(**{**cb_params, \"use_best_model\": False, \"od_type\": None, \"verbose\": False})\n",
        "cb_full.fit(Pool(X, y, cat_features=cat_features_idx))\n",
        "p_test = cb_full.predict_proba(Xt)[:,1]\n",
        "\n",
        "print(\"\\nTEST prob-metrics:\", {\"AUROC\": roc_auc_score(y_test, p_test),\n",
        "                              \"AUPRC\": average_precision_score(y_test, p_test)})\n",
        "yhat = (p_test >= BEST_THR).astype(int)\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, yhat, labels=[0,1]).ravel()\n",
        "print(\"\\nTEST @ best OOF threshold:\",\n",
        "      {\"threshold\": BEST_THR, \"TN\": int(tn), \"FP\": int(fp), \"FN\": int(fn), \"TP\": int(tp),\n",
        "       \"precision\": precision_score(y_test, yhat, zero_division=0),\n",
        "       \"recall\":    recall_score(y_test, yhat, zero_division=0),\n",
        "       \"f1\":        f1_score(y_test, yhat, zero_division=0)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s44iaGfm_qRe",
        "outputId": "313fd03c-36cf-476a-c1b5-8bf63c0bba93"
      },
      "outputs": [],
      "source": [
        "# SAVE for single-pass CatBoost run\n",
        "import os, json, hashlib\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "OUTDIR = \"/content/drive/MyDrive/CIS_678_final_project/catboost_rich6h\"\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "\n",
        "LABEL = \"label6h\"\n",
        "\n",
        "def mk_row_id(df: pd.DataFrame) -> pd.Series:\n",
        "    ts = pd.to_datetime(df[\"t\"], errors=\"coerce\").astype(str)\n",
        "    keys = df[\"subject_id\"].astype(str) + \"|\" + df[\"hadm_id\"].astype(str) + \"|\" + df[\"icustay_id\"].astype(str) + \"|\" + ts\n",
        "    return keys.apply(lambda s: hashlib.md5(s.encode()).hexdigest())\n",
        "\n",
        "# Optional predicted-risk lags\n",
        "PRED_LAG_COLS = [c for c in [\"pred_lag1\",\"pred_lag2\",\"pred_lag1_missing\",\"pred_lag2_missing\"]\n",
        "                 if c in train_tab.columns and c in test_tab.columns]\n",
        "\n",
        "# TRAIN OOF table (keep only rows with OOF preds)\n",
        "train_keys = [\"subject_id\",\"hadm_id\",\"icustay_id\",\"t\", LABEL]\n",
        "keep_tr = [c for c in train_keys + PRED_LAG_COLS + FEATURES if c in train_tab.columns]\n",
        "oof_df = train_tab.loc[:, keep_tr].copy()\n",
        "oof_df[\"row_id\"]   = mk_row_id(oof_df)\n",
        "oof_df[\"p_cb_oof\"] = oof\n",
        "oof_df[\"fold_id\"]  = fold_ids if \"fold_ids\" in globals() else -1\n",
        "oof_df = oof_df.loc[~pd.isna(oof_df[\"p_cb_oof\"])].reset_index(drop=True)\n",
        "\n",
        "oof_path = os.path.join(OUTDIR, \"cb_level1_oof_train_single.csv\")\n",
        "oof_df.to_csv(oof_path, index=False)\n",
        "\n",
        "# EST predictions table\n",
        "test_keys = [\"subject_id\",\"hadm_id\",\"icustay_id\",\"t\", LABEL]\n",
        "keep_te = [c for c in test_keys + PRED_LAG_COLS + FEATURES if c in test_tab.columns]\n",
        "test_df = test_tab.loc[:, keep_te].copy()\n",
        "test_df[\"row_id\"]    = mk_row_id(test_df)\n",
        "test_df[\"p_cb_test\"] = p_test\n",
        "\n",
        "test_path = os.path.join(OUTDIR, \"cb_level1_preds_test_single.csv\")\n",
        "test_df.to_csv(test_path, index=False)\n",
        "\n",
        "# Threshold sweep + chosen threshold\n",
        "if \"thr_table\" in globals() and \"BEST_THR\" in globals() and \"best_row\" in globals():\n",
        "    thr_path = os.path.join(OUTDIR, \"cb_oof_threshold_sweep_single.csv\")\n",
        "    thr_table.to_csv(thr_path, index=False)\n",
        "    with open(os.path.join(OUTDIR, \"cb_selected_threshold_single.json\"), \"w\") as f:\n",
        "        json.dump({\n",
        "            \"best_threshold\": float(BEST_THR),\n",
        "            \"oof_precision\": float(best_row[\"precision\"]),\n",
        "            \"oof_recall\": float(best_row[\"recall\"]),\n",
        "            \"oof_f1\": float(best_row[\"f1\"])\n",
        "        }, f, indent=2)\n",
        "\n",
        "# Features actually used\n",
        "feat_list_path = os.path.join(OUTDIR, \"cb_features_used_single.txt\")\n",
        "with open(feat_list_path, \"w\") as f:\n",
        "    for c in FEATURES:\n",
        "        f.write(c + \"\\n\")\n",
        "\n",
        "schema_cols = [\"subject_id\",\"hadm_id\",\"icustay_id\",\"t\", LABEL] + FEATURES\n",
        "schema_cols = [c for c in schema_cols if c in train_tab.columns]\n",
        "schema = train_tab[schema_cols].dtypes.astype(str).reset_index()\n",
        "schema.columns = [\"column\",\"dtype\"]\n",
        "schema_path = os.path.join(OUTDIR, \"cb_feature_schema_single.csv\")\n",
        "schema.to_csv(schema_path, index=False)\n",
        "\n",
        "\n",
        "model_path = os.path.join(OUTDIR, \"cb_full.cbm\")\n",
        "cb_full.save_model(model_path)\n",
        "\n",
        "params_path = os.path.join(OUTDIR, \"cb_params_single.json\")\n",
        "with open(params_path, \"w\") as f:\n",
        "    json.dump({**cb_params, \"class_weights\":[1.0, float(scale_pos_weight)]}, f, indent=2)\n",
        "\n",
        "meta = {\n",
        "    \"stage\": \"single\",\n",
        "    \"rows_train_oof\": int(len(oof_df)),\n",
        "    \"rows_test\": int(len(test_df)),\n",
        "    \"positive_rate_train\": float(train_tab[LABEL].mean()),\n",
        "    \"positive_rate_test\": float(test_tab[LABEL].mean()),\n",
        "    \"features_used_count\": int(len(FEATURES)),\n",
        "    \"has_pred_lags\": bool(len(PRED_LAG_COLS) > 0)\n",
        "}\n",
        "with open(os.path.join(OUTDIR, \"cb_metadata_single.json\"), \"w\") as f:\n",
        "    json.dump(meta, f, indent=2)\n",
        "\n",
        "with open(os.path.join(OUTDIR, \"README_single.txt\"), \"w\") as f:\n",
        "    f.write(readme_txt)\n",
        "\n",
        "print(\"Saved:\")\n",
        "print(\" -\", oof_path)\n",
        "print(\" -\", test_path)\n",
        "print(\" -\", feat_list_path, \" & \", schema_path)\n",
        "print(\" -\", model_path, \" & \", params_path)\n",
        "print(\" - cb_metadata_single.json, README_single.txt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "b. TF-IDF + LR model for notes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, numpy as np, pandas as pd, warnings, json, hashlib\n",
        "from sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "OUTDIR = \"/content/drive/MyDrive/CIS_678_final_project\"\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "\n",
        "TRAIN_FILE = os.path.join(OUTDIR, \"notes_train_sample.csv.csv\")\n",
        "TEST_FILE  = os.path.join(OUTDIR, \"notes_test_sample.csv.csv\")\n",
        "\n",
        "def read_text(path):\n",
        "    df = pd.read_csv(path)\n",
        "    for c in [\"subject_id\",\"hadm_id\",\"icustay_id\",\"t\",\"notes_24h\",\"label6h\"]:\n",
        "        assert c in df.columns, f\"Missing {c}\"\n",
        "    df[\"notes_24h\"] = df[\"notes_24h\"].fillna(\"\")\n",
        "    df[\"t\"] = pd.to_datetime(df[\"t\"])\n",
        "    return df\n",
        "\n",
        "tr = read_text(TRAIN_FILE)\n",
        "te = read_text(TEST_FILE)\n",
        "tr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, numpy as np, pandas as pd, warnings, json, hashlib\n",
        "from sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "OUTDIR = \"/content/drive/MyDrive/CIS_678_final_project\"\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "\n",
        "TRAIN_FILE = os.path.join(OUTDIR, \"notes_train_sample.csv.csv\")\n",
        "TEST_FILE  = os.path.join(OUTDIR, \"notes_test_sample.csv.csv\")\n",
        "\n",
        "def read_text(path):\n",
        "    df = pd.read_csv(path)\n",
        "    for c in [\"subject_id\",\"hadm_id\",\"icustay_id\",\"t\",\"notes_24h\",\"label6h\"]:\n",
        "        assert c in df.columns, f\"Missing {c}\"\n",
        "    df[\"notes_24h\"] = df[\"notes_24h\"].fillna(\"\")\n",
        "    df[\"t\"] = pd.to_datetime(df[\"t\"])\n",
        "    return df\n",
        "\n",
        "tr = read_text(TRAIN_FILE)\n",
        "te = read_text(TEST_FILE)\n",
        "\n",
        "GROUP = [\"subject_id\",\"hadm_id\",\"icustay_id\"]\n",
        "\n",
        "def add_text_lags(df):\n",
        "    df = df.sort_values(GROUP + [\"t\"]).copy()\n",
        "    g = df.groupby(GROUP, sort=False)\n",
        "    df[\"notes_prev1\"] = g[\"notes_24h\"].shift(1).fillna(\"\")\n",
        "    df[\"notes_prev2\"] = g[\"notes_24h\"].shift(2).fillna(\"\")\n",
        "    df[\"notes_combo\"] = (df[\"notes_prev2\"] + \" [SEP] \" +\n",
        "                         df[\"notes_prev1\"] + \" [SEP] \" +\n",
        "                         df[\"notes_24h\"])\n",
        "    return df\n",
        "\n",
        "tr = add_text_lags(tr)\n",
        "te = add_text_lags(te)\n",
        "\n",
        "# time-ordered, admission-disjoint folds\n",
        "K = 5\n",
        "order = np.argsort(tr[\"t\"].values)\n",
        "fold_ids = np.full(len(tr), -1, int)\n",
        "for k, idx in enumerate(np.array_split(order, K)):\n",
        "    fold_ids[idx] = k\n",
        "\n",
        "y_tr = tr[\"label6h\"].astype(int).values\n",
        "oof  = np.full(len(tr), np.nan, float)\n",
        "\n",
        "# fixed hashing space avoids tiny per-fold vocab\n",
        "hv = HashingVectorizer(\n",
        "    n_features=2**20,\n",
        "    alternate_sign=False,\n",
        "    ngram_range=(1,2),\n",
        "    norm=None,                 \n",
        "    strip_accents=\"unicode\",\n",
        "    lowercase=True\n",
        ")\n",
        "\n",
        "for k in range(1, K):\n",
        "    va_idx = np.where(fold_ids == k)[0]\n",
        "    tr_pool_idx = np.where(fold_ids <  k)[0]\n",
        "    va_hadm = set(tr.loc[va_idx, \"hadm_id\"])\n",
        "    tr_idx = tr_pool_idx[~tr.loc[tr_pool_idx, \"hadm_id\"].isin(va_hadm)]\n",
        "    if len(tr_idx)==0 or len(va_idx)==0:\n",
        "        continue\n",
        "\n",
        "    X_tr_h = hv.transform(tr.loc[tr_idx, \"notes_combo\"].astype(str))\n",
        "    X_va_h = hv.transform(tr.loc[va_idx, \"notes_combo\"].astype(str))\n",
        "\n",
        "    tfidf = TfidfTransformer(sublinear_tf=True, smooth_idf=True)\n",
        "    X_tr  = tfidf.fit_transform(X_tr_h)\n",
        "    X_va  = tfidf.transform(X_va_h)\n",
        "\n",
        "    y_tr_fold = y_tr[tr_idx]\n",
        "    lr = LogisticRegression(\n",
        "        solver=\"saga\", penalty=\"l2\", C=2.0,\n",
        "        max_iter=1000, class_weight=\"balanced\", n_jobs=-1,\n",
        "        random_state=42\n",
        "    )\n",
        "    lr.fit(X_tr, y_tr_fold)\n",
        "    oof[va_idx] = lr.predict_proba(X_va)[:,1]\n",
        "\n",
        "used = ~np.isnan(oof)\n",
        "print(f\"OOF coverage: used={used.sum()}  nan={(~used).sum()}\")\n",
        "print(\"TFIDF-Hash LR OOF AUROC/AUPRC:\",\n",
        "      roc_auc_score(y_tr[used], oof[used]),\n",
        "      average_precision_score(y_tr[used], oof[used]))\n",
        "\n",
        "# final fit on full training to TEST \n",
        "X_full_tr_h = hv.transform(tr[\"notes_combo\"].astype(str))\n",
        "X_full_te_h = hv.transform(te[\"notes_combo\"].astype(str))\n",
        "tfidf_full  = TfidfTransformer(sublinear_tf=True, smooth_idf=True).fit(X_full_tr_h)\n",
        "X_full_tr   = tfidf_full.transform(X_full_tr_h)\n",
        "X_full_te   = tfidf_full.transform(X_full_te_h)\n",
        "\n",
        "lr_final = LogisticRegression(\n",
        "    solver=\"saga\", penalty=\"l2\", C=2.0,\n",
        "    max_iter=1000, class_weight=\"balanced\", n_jobs=-1, random_state=42\n",
        ").fit(X_full_tr, y_tr)\n",
        "\n",
        "y_te = te[\"label6h\"].astype(int).values\n",
        "p_text_tr_insample = lr_final.predict_proba(X_full_tr)[:,1] \n",
        "p_text_te          = lr_final.predict_proba(X_full_te)[:,1]\n",
        "\n",
        "print(\"Text TRAIN (in-sample):\",\n",
        "      {\"AUROC\": roc_auc_score(y_tr, p_text_tr_insample),\n",
        "       \"AUPRC\": average_precision_score(y_tr, p_text_tr_insample)})\n",
        "print(\"Text TEST:\",\n",
        "      {\"AUROC\": roc_auc_score(y_te, p_text_te),\n",
        "       \"AUPRC\": average_precision_score(y_te, p_text_te)})\n",
        "\n",
        "# threshold sweep\n",
        "def sweep_thresholds(y_true, p, grid=None):\n",
        "    grid = grid or np.arange(0.1, 1.0, 0.1)  \n",
        "    rows = []\n",
        "    for thr in grid:\n",
        "        yhat = (p >= thr).astype(int)\n",
        "        rows.append({\n",
        "            \"threshold\": float(thr),\n",
        "            \"precision\": precision_score(y_true, yhat, zero_division=0),\n",
        "            \"recall\":    recall_score(y_true, yhat, zero_division=0),\n",
        "            \"f1\":        f1_score(y_true, yhat, zero_division=0)\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# OOF sweep, choose best-F1 threshold\n",
        "thr_oof = sweep_thresholds(y_tr[used], oof[used])\n",
        "best_row = thr_oof.sort_values([\"f1\",\"recall\",\"precision\"], ascending=False).iloc[0]\n",
        "BEST_THR = float(best_row[\"threshold\"])\n",
        "\n",
        "print(\"\\n[OOF] threshold sweep (0.1..0.9):\")\n",
        "print(thr_oof)\n",
        "print(f\"\\nSelected OOF THRESH={BEST_THR:.2f} | \"\n",
        "      f\"P={best_row['precision']:.3f} R={best_row['recall']:.3f} F1={best_row['f1']:.3f}\")\n",
        "\n",
        "# apply OOF-best threshold to TEST \n",
        "yhat_test = (p_text_te >= BEST_THR).astype(int)\n",
        "tn, fp, fn, tp = confusion_matrix(y_te, yhat_test, labels=[0,1]).ravel()\n",
        "prec = precision_score(y_te, yhat_test, zero_division=0)\n",
        "rec  = recall_score(y_te, yhat_test, zero_division=0)\n",
        "f1   = f1_score(y_te, yhat_test, zero_division=0)\n",
        "\n",
        "print(\"\\n[TEST] @ OOF-best threshold:\",\n",
        "      {\"threshold\": BEST_THR, \"TN\": int(tn), \"FP\": int(fp), \"FN\": int(fn), \"TP\": int(tp),\n",
        "       \"precision\": round(prec,4), \"recall\": round(rec,4), \"f1\": round(f1,4)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save the files for futher use\n",
        "import os, json, hashlib\n",
        "import pandas as pd, numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "OUTDIR = \"/content/drive/MyDrive/CIS_678_final_project\"\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "\n",
        "def sweep_thresholds(y_true, p, grid=None):\n",
        "    grid = grid or np.linspace(0.1, 0.9, 9)  \n",
        "    rows = []\n",
        "    for thr in grid:\n",
        "        yhat = (p >= thr).astype(int)\n",
        "        rows.append({\n",
        "            \"threshold\": float(thr),\n",
        "            \"precision\": precision_score(y_true, yhat, zero_division=0),\n",
        "            \"recall\":    recall_score(y_true, yhat, zero_division=0),\n",
        "            \"f1\":        f1_score(y_true, yhat, zero_division=0),\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "def mk_row_id(df: pd.DataFrame) -> pd.Series:\n",
        "    keys = (df[\"subject_id\"].astype(str) + \"|\" +\n",
        "            df[\"hadm_id\"].astype(str)    + \"|\" +\n",
        "            df[\"icustay_id\"].astype(str) + \"|\" +\n",
        "            pd.to_datetime(df[\"t\"]).astype(str))\n",
        "    return keys.apply(lambda s: hashlib.md5(s.encode()).hexdigest())\n",
        "\n",
        "assert {\"subject_id\",\"hadm_id\",\"icustay_id\",\"t\",\"label6h\"}.issubset(tr.columns)\n",
        "assert {\"subject_id\",\"hadm_id\",\"icustay_id\",\"t\",\"label6h\"}.issubset(te.columns)\n",
        "assert len(oof) == len(tr), \"oof length != train rows\"\n",
        "assert len(p_text_te) == len(te), \"test probs length != test rows\"\n",
        "\n",
        "\n",
        "thr_table = sweep_thresholds(y_tr[used], oof[used])\n",
        "best_row = thr_table.sort_values([\"f1\",\"recall\",\"precision\"], ascending=False).iloc[0]\n",
        "BEST_THR = float(best_row[\"threshold\"])\n",
        "print(\"[OOF] threshold sweep (0.1..0.9):\\n\", thr_table)\n",
        "print(f\"\\nSelected OOF THRESH={BEST_THR:.2f} | \"\n",
        "      f\"P={best_row['precision']:.3f} R={best_row['recall']:.3f} F1={best_row['f1']:.3f}\")\n",
        "\n",
        "\n",
        "tr_oof = tr.loc[used, [\"subject_id\",\"hadm_id\",\"icustay_id\",\"t\",\"label6h\"]].copy()\n",
        "tr_oof[\"row_id\"] = mk_row_id(tr_oof)\n",
        "tr_oof[\"p_text\"] = oof[used]\n",
        "tr_oof_path = os.path.join(OUTDIR, \"oof_text_hash_tfidf_lr.csv\")\n",
        "tr_oof.to_csv(tr_oof_path, index=False)\n",
        "\n",
        "\n",
        "te_out = te[[\"subject_id\",\"hadm_id\",\"icustay_id\",\"t\",\"label6h\"]].copy()\n",
        "te_out[\"row_id\"] = mk_row_id(te_out)\n",
        "te_out[\"p_text\"] = p_text_te\n",
        "te_out_path = os.path.join(OUTDIR, \"pred_text_hash_tfidf_lr_test.csv\")\n",
        "te_out.to_csv(te_out_path, index=False)\n",
        "\n",
        "\n",
        "thr_oof_path = os.path.join(OUTDIR, \"text_oof_thresholds.csv\")\n",
        "thr_table.to_csv(thr_oof_path, index=False)\n",
        "\n",
        "selected = {\n",
        "    \"selected_oof_threshold\": float(BEST_THR),\n",
        "    \"oof_precision\": float(best_row[\"precision\"]),\n",
        "    \"oof_recall\": float(best_row[\"recall\"]),\n",
        "    \"oof_f1\": float(best_row[\"f1\"]),\n",
        "    \"pinned_test_threshold\": 0.10\n",
        "}\n",
        "with open(os.path.join(OUTDIR, \"text_selected_threshold.json\"), \"w\") as f:\n",
        "    json.dump(selected, f, indent=2)\n",
        "\n",
        "print(\"Saved:\")\n",
        "print(\" -\", tr_oof_path)\n",
        "print(\" -\", te_out_path)\n",
        "print(\" -\", thr_oof_path, \" + text_selected_threshold.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "c. Fusion model (Catboost + TF-IDF LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, json, hashlib\n",
        "import numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, average_precision_score, precision_score,\n",
        "    recall_score, f1_score, confusion_matrix\n",
        ")\n",
        "\n",
        "BASE   = \"/content/drive/MyDrive/CIS_678_final_project\"\n",
        "CB_DIR = os.path.join(BASE, \"catboost_rich6h\")       \n",
        "OUTDIR = os.path.join(BASE, \"fusion_level2\")\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "\n",
        "DATA = Path(BASE)\n",
        "\n",
        "def read_tabular(fname):  \n",
        "    return pd.read_csv(DATA/fname, parse_dates=[\"t\"], na_values=[\"NULL\"])\n",
        "\n",
        "def read_text(fname):\n",
        "    return pd.read_csv(DATA/fname, na_values=[\"NULL\"])\n",
        "\n",
        "def report_metrics(y_true, p):\n",
        "    return {\n",
        "        \"AUROC\": roc_auc_score(y_true, p),\n",
        "        \"AUPRC\": average_precision_score(y_true, p)\n",
        "    }\n",
        "\n",
        "def mk_row_id(df):\n",
        "    ts = pd.to_datetime(df[\"t\"], errors=\"coerce\").astype(str)\n",
        "    keys = (df[\"subject_id\"].astype(str) + \"|\" +\n",
        "            df[\"hadm_id\"].astype(str)    + \"|\" +\n",
        "            df[\"icustay_id\"].astype(str) + \"|\" +\n",
        "            ts)\n",
        "    return keys.apply(lambda s: hashlib.md5(s.encode()).hexdigest())\n",
        "\n",
        "\n",
        "\n",
        "cb_tr_path = os.path.join(CB_DIR, \"cb_level1_oof_train_single.csv\")\n",
        "cb_te_path = os.path.join(CB_DIR, \"cb_level1_preds_test_single.csv\")\n",
        "tx_tr_path = os.path.join(BASE, \"oof_text_hash_tfidf_lr.csv\")\n",
        "tx_te_path = os.path.join(BASE, \"pred_text_hash_tfidf_lr_test.csv\")\n",
        "\n",
        "cb_tr = pd.read_csv(cb_tr_path, parse_dates=[\"t\"])\n",
        "cb_te = pd.read_csv(cb_te_path, parse_dates=[\"t\"])\n",
        "tx_tr = pd.read_csv(tx_tr_path, parse_dates=[\"t\"])\n",
        "tx_te = pd.read_csv(tx_te_path, parse_dates=[\"t\"])\n",
        "\n",
        "# ensure row_id\n",
        "for df in (cb_tr, cb_te, tx_tr, tx_te):\n",
        "    if \"row_id\" not in df.columns:\n",
        "        df[\"row_id\"] = mk_row_id(df)\n",
        "\n",
        "\n",
        "tr = cb_tr.merge(tx_tr[[\"row_id\",\"p_text\"]], on=\"row_id\", how=\"left\")\n",
        "te = cb_te.merge(tx_te[[\"row_id\",\"p_text\"]], on=\"row_id\", how=\"left\")\n",
        "\n",
        "# basic sanity\n",
        "assert {\"subject_id\",\"hadm_id\",\"icustay_id\",\"t\",\"label6h\",\"p_cb_oof\"}.issubset(tr.columns), \"Missing columns in cb OOF train\"\n",
        "assert {\"subject_id\",\"hadm_id\",\"icustay_id\",\"t\",\"label6h\",\"p_cb_test\"}.issubset(te.columns), \"Missing columns in cb TEST\"\n",
        "\n",
        "\n",
        "tr = tr.rename(columns={\"p_cb_oof\": \"p_cb\"})  \n",
        "te = te.rename(columns={\"p_cb_test\": \"p_cb\"}) \n",
        "\n",
        "# has_text + neutral imputation\n",
        "tr[\"has_text\"] = (~tr[\"p_text\"].isna()).astype(int)\n",
        "te[\"has_text\"] = (~te[\"p_text\"].isna()).astype(int)\n",
        "\n",
        "y_tr = tr[\"label6h\"].astype(int).to_numpy()\n",
        "y_te = te[\"label6h\"].astype(int).to_numpy()\n",
        "prior = float(y_tr.mean())\n",
        "\n",
        "tr[\"p_text\"] = tr[\"p_text\"].fillna(prior)\n",
        "te[\"p_text\"] = te[\"p_text\"].fillna(prior)\n",
        "\n",
        "# save aligned inputs\n",
        "tr.to_csv(os.path.join(OUTDIR, \"aligned_level1_train.csv\"), index=False)\n",
        "te.to_csv(os.path.join(OUTDIR, \"aligned_level1_test.csv\"), index=False)\n",
        "\n",
        "-\n",
        "FUSED_FEATS = [\"p_cb\", \"p_text\", \"has_text\"]  \n",
        "X_tr = tr[FUSED_FEATS].replace([np.inf,-np.inf], np.nan).fillna(0.0)\n",
        "X_te = te[FUSED_FEATS].replace([np.inf,-np.inf], np.nan).fillna(0.0)\n",
        "\n",
        "# tiny extra guard\n",
        "assert list(X_tr.columns) == list(X_te.columns), \"Train/Test feature columns differ\"\n",
        "\n",
        "\n",
        "tvals = pd.to_datetime(tr[\"t\"]).to_numpy()\n",
        "order = np.argsort(tvals)\n",
        "K = 5\n",
        "fold_ids = np.full(len(tr), -1, int)\n",
        "for k, idx in enumerate(np.array_split(order, K)):\n",
        "    fold_ids[idx] = k\n",
        "\n",
        "oof_fused = np.full(len(tr), np.nan, float)\n",
        "for k in range(1, K):\n",
        "    va_idx = np.where(fold_ids == k)[0]\n",
        "    tr_pool_idx = np.where(fold_ids <  k)[0]\n",
        "    # HADM disjoint\n",
        "    va_hadm = set(tr.loc[va_idx, \"hadm_id\"])\n",
        "    tr_idx = tr_pool_idx[~tr.loc[tr_pool_idx, \"hadm_id\"].isin(va_hadm)]\n",
        "    if len(tr_idx)==0 or len(va_idx)==0:\n",
        "        continue\n",
        "    meta = LogisticRegression(solver=\"liblinear\", penalty=\"l2\", C=1.0,\n",
        "                              class_weight=\"balanced\", max_iter=1000, random_state=42)\n",
        "    meta.fit(X_tr.iloc[tr_idx], y_tr[tr_idx])\n",
        "    oof_fused[va_idx] = meta.predict_proba(X_tr.iloc[va_idx])[:,1]\n",
        "\n",
        "used = ~np.isnan(oof_fused)\n",
        "print(\"FUSION OOF coverage:\", used.sum(), \"/\", len(tr))\n",
        "if used.sum() == 0:\n",
        "    raise RuntimeError(\"No OOF_fused produced; check joins/columns.\")\n",
        "\n",
        "print(\"FUSION OOF AUROC/AUPRC:\",\n",
        "      roc_auc_score(y_tr[used], oof_fused[used]),\n",
        "      average_precision_score(y_tr[used], oof_fused[used]))\n",
        "\n",
        "\n",
        "meta_full = LogisticRegression(solver=\"liblinear\", penalty=\"l2\", C=1.0,\n",
        "                               class_weight=\"balanced\", max_iter=1000, random_state=42).fit(X_tr, y_tr)\n",
        "p_fused_test = meta_full.predict_proba(X_te)[:,1]\n",
        "print(\"FUSION TEST AUROC/AUPRC:\",\n",
        "      roc_auc_score(y_te, p_fused_test),\n",
        "      average_precision_score(y_te, p_fused_test))\n",
        "\n",
        "\n",
        "def sweep_thresholds(y_true, p, grid=None):\n",
        "    grid = grid or np.linspace(0.05, 0.95, 19)\n",
        "    rows=[]\n",
        "    for thr in grid:\n",
        "        yhat = (p >= thr).astype(int)\n",
        "        rows.append({\"threshold\": float(thr),\n",
        "                     \"precision\": precision_score(y_true, yhat, zero_division=0),\n",
        "                     \"recall\":    recall_score(y_true, yhat, zero_division=0),\n",
        "                     \"f1\":        f1_score(y_true, yhat, zero_division=0)})\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "thr_table = sweep_thresholds(y_tr[used], oof_fused[used])\n",
        "if thr_table.empty:\n",
        "    raise RuntimeError(\"Threshold table is empty; check OOF predictions.\")\n",
        "\n",
        "best_row = thr_table.sort_values([\"f1\",\"recall\",\"precision\"], ascending=False).iloc[0]\n",
        "BEST_THR = float(best_row[\"threshold\"])\n",
        "print(\"\\n[OOF_fused] threshold sweep:\\n\", thr_table)\n",
        "print(f\"\\nSelected THR={BEST_THR:.2f} | \"\n",
        "      f\"P={float(best_row['precision']):.3f} R={float(best_row['recall']):.3f} F1={float(best_row['f1']):.3f}\")\n",
        "\n",
        "\n",
        "yhat = (p_fused_test >= BEST_THR).astype(int)\n",
        "tn, fp, fn, tp = confusion_matrix(y_te, yhat, labels=[0,1]).ravel()\n",
        "print(\"\\nTEST @ OOF_fused threshold:\",\n",
        "      {\"threshold\": BEST_THR, \"TN\": int(tn), \"FP\": int(fp), \"FN\": int(fn), \"TP\": int(tp),\n",
        "       \"precision\": precision_score(y_te, yhat, zero_division=0),\n",
        "       \"recall\":    recall_score(y_te, yhat, zero_division=0),\n",
        "       \"f1\":        f1_score(y_te, yhat, zero_division=0)})\n",
        "\n",
        "# save artifacts\n",
        "tr_out = tr.loc[used, [\"subject_id\",\"hadm_id\",\"icustay_id\",\"t\",\"label6h\",\"row_id\"]].copy()\n",
        "tr_out[\"p_fused_oof\"] = oof_fused[used]\n",
        "tr_out.to_csv(os.path.join(OUTDIR, \"oof_fused_train.csv\"), index=False)\n",
        "\n",
        "te_out = te[[\"subject_id\",\"hadm_id\",\"icustay_id\",\"t\",\"label6h\",\"row_id\"]].copy()\n",
        "te_out[\"p_fused_test\"] = p_fused_test\n",
        "te_out.to_csv(os.path.join(OUTDIR, \"pred_fused_test.csv\"), index=False)\n",
        "\n",
        "thr_table.to_csv(os.path.join(OUTDIR, \"fusion_oof_thresholds.csv\"), index=False)\n",
        "with open(os.path.join(OUTDIR, \"fusion_selected_threshold.json\"), \"w\") as f:\n",
        "    json.dump({\n",
        "        \"best_threshold\": BEST_THR,\n",
        "        \"oof_precision\": float(best_row[\"precision\"]),\n",
        "        \"oof_recall\": float(best_row[\"recall\"]),\n",
        "        \"oof_f1\": float(best_row[\"f1\"])\n",
        "    }, f, indent=2)\n",
        "\n",
        "print(\"\\nSaved fusion files to:\", OUTDIR)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
